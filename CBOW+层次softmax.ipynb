{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea73daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import time\n",
    "\n",
    "# ---------------------- 工具函数 ----------------------\n",
    "def safe_sigmoid(x):\n",
    "    \"\"\"数值稳定的Sigmoid函数\"\"\"\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -100, 100)))\n",
    "\n",
    "def safe_log(x, eps=1e-8):\n",
    "    \"\"\"数值稳定的对数函数\"\"\"\n",
    "    return np.log(np.clip(x, eps, 1.0 - eps))\n",
    "\n",
    "# ---------------------- 数据预处理 ----------------------\n",
    "def load_text(file_path, sample_ratio=1.0):\n",
    "    \"\"\"加载并采样文本\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().strip().split()\n",
    "    if sample_ratio < 1.0:\n",
    "        text = text[:int(len(text) * sample_ratio)]\n",
    "    return [word.lower() for word in text]\n",
    "\n",
    "def build_vocab(tokenized_text, min_count=5):\n",
    "    \"\"\"构建词汇表和词频统计\"\"\"\n",
    "    word_freq = {}\n",
    "    for word in tokenized_text:\n",
    "        word_freq[word] = word_freq.get(word, 0) + 1\n",
    "    # 过滤低频词\n",
    "    word_freq = {w: f for w, f in word_freq.items() if f >= min_count}\n",
    "    # 构建词汇表\n",
    "    id2word = [\"[UNK]\"]\n",
    "    word2id = {\"[UNK]\": 0}\n",
    "    idx = 1\n",
    "    for word in word_freq:\n",
    "        word2id[word] = idx\n",
    "        id2word.append(word)\n",
    "        idx += 1\n",
    "    return word_freq, id2word, word2id\n",
    "\n",
    "# ---------------------- 生成训练数据 ----------------------\n",
    "def generate_train_data(tokenized_text, word2id, window_size=5):\n",
    "    \"\"\"生成 (中心词ID, 上下文ID列表) 训练数据\"\"\"\n",
    "    train_data = []\n",
    "    for i in range(len(tokenized_text)):\n",
    "        center_word = tokenized_text[i]\n",
    "        center_id = word2id.get(center_word, 0)\n",
    "        if center_id == 0:  # 跳过未知词\n",
    "            continue\n",
    "        # 随机窗口大小\n",
    "        curr_window = np.random.randint(1, window_size + 1)\n",
    "        context_ids = []\n",
    "        # 采集上下文词\n",
    "        start = max(0, i - curr_window)\n",
    "        end = min(len(tokenized_text), i + curr_window + 1)\n",
    "        for j in range(start, end):\n",
    "            if j == i:\n",
    "                continue\n",
    "            context_word = tokenized_text[j]\n",
    "            ctx_id = word2id.get(context_word, 0)\n",
    "            if ctx_id != 0:\n",
    "                context_ids.append(ctx_id)\n",
    "        if len(context_ids) > 0:\n",
    "            train_data.append((center_id, context_ids))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2092ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffmanNode:\n",
    "    \"\"\"霍夫曼树节点定义\"\"\"\n",
    "    def __init__(self, word=None, freq=0):\n",
    "        self.word = word\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.code = []       # 路径编码\n",
    "        self.param = None    # 节点参数向量\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq  # 用于堆排序\n",
    "\n",
    "def build_huffman_tree(word_freq):\n",
    "    \"\"\"构建霍夫曼树并返回路径信息\"\"\"\n",
    "    # 初始化堆\n",
    "    heap = [HuffmanNode(word=w, freq=f) for w, f in word_freq.items()]\n",
    "    heapq.heapify(heap)\n",
    "    \n",
    "    # 合并节点\n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        merged = HuffmanNode(freq=left.freq + right.freq)\n",
    "        merged.left, merged.right = left, right\n",
    "        left.parent = merged\n",
    "        right.parent = merged\n",
    "        heapq.heappush(heap, merged)\n",
    "    \n",
    "    root = heap[0]\n",
    "    \n",
    "    # 生成路径编码\n",
    "    word_to_path = {}\n",
    "    def assign_codes(node, code=[]):\n",
    "        if node is None:\n",
    "            return\n",
    "        if node.word is not None:\n",
    "            node.code = code.copy()\n",
    "            path_nodes = []\n",
    "            current = node.parent\n",
    "            while current is not None:\n",
    "                path_nodes.append(current)\n",
    "                current = current.parent\n",
    "            word_to_path[node.word] = {\n",
    "                'nodes': path_nodes[::-1],  # 从根到叶子\n",
    "                'codes': code.copy()\n",
    "            }\n",
    "        assign_codes(node.left, code + [0])\n",
    "        assign_codes(node.right, code + [1])\n",
    "    \n",
    "    assign_codes(root)\n",
    "    return root, word_to_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78abcb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(vocab_size, embedding_dim, huffman_tree):\n",
    "    \"\"\"初始化词向量和霍夫曼树节点参数\"\"\"\n",
    "    # 初始化词向量\n",
    "    input_embeddings = np.random.randn(vocab_size, embedding_dim) * 0.01\n",
    "    \n",
    "    # 初始化霍夫曼树内部节点参数\n",
    "    node_params = {}\n",
    "    def init_node_params(node):\n",
    "        if node is None:\n",
    "            return\n",
    "        if node.word is None:  # 内部节点\n",
    "            node.param = np.random.randn(embedding_dim) * 0.01\n",
    "            node_params[node] = node.param\n",
    "        init_node_params(node.left)\n",
    "        init_node_params(node.right)\n",
    "    init_node_params(huffman_tree)\n",
    "    \n",
    "    return input_embeddings, node_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770fb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_softmax_loss(center_id, context_ids, input_emb, node_params, word_to_path, id2word):\n",
    "    \"\"\"计算层次Softmax损失和梯度\"\"\"\n",
    "    # 计算上下文向量h\n",
    "    h = np.mean([input_emb[ctx_id] for ctx_id in context_ids], axis=0)\n",
    "    \n",
    "    # 获取中心词的路径信息\n",
    "    center_word = id2word[center_id]\n",
    "    path_info = word_to_path.get(center_word, None)\n",
    "    if path_info is None:\n",
    "        return 0.0, np.zeros_like(h), {}\n",
    "    \n",
    "    # 遍历路径计算损失\n",
    "    total_loss = 0.0\n",
    "    grad_h = np.zeros_like(h)\n",
    "    node_grads = {node: np.zeros_like(param) for node, param in node_params.items()}\n",
    "    \n",
    "    for node, code in zip(path_info['nodes'], path_info['codes']):\n",
    "        theta = node.param\n",
    "        prob = safe_sigmoid(np.dot(theta, h))\n",
    "        label = code\n",
    "        \n",
    "        # 损失计算\n",
    "        loss = - (label * safe_log(prob) + (1 - label) * safe_log(1 - prob))\n",
    "        total_loss += loss\n",
    "        \n",
    "        # 梯度计算\n",
    "        delta = (prob - label)\n",
    "        grad_h += delta * theta\n",
    "        node_grads[node] += delta * h\n",
    "    \n",
    "    return total_loss, grad_h, node_grads\n",
    "\n",
    "def train_model(train_data, input_emb, node_params, word_to_path, id2word, num_epochs=5, lr=0.025):\n",
    "    \"\"\"训练循环\"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(train_data)\n",
    "        total_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for idx, (center_id, context_ids) in enumerate(train_data):\n",
    "            # 计算损失和梯度\n",
    "            loss, grad_h, grads = hierarchical_softmax_loss(\n",
    "                center_id, context_ids, input_emb, node_params, word_to_path, id2word\n",
    "            )\n",
    "            total_loss += loss\n",
    "            \n",
    "            # 更新参数\n",
    "            for ctx_id in context_ids:\n",
    "                input_emb[ctx_id] -= lr * grad_h / len(context_ids)\n",
    "            for node in grads:\n",
    "                node.param -= lr * grads[node]\n",
    "            \n",
    "            # 打印进度\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                avg_loss = total_loss / (idx + 1)\n",
    "                speed = (time.time() - start_time) / (idx + 1)\n",
    "                print(f\"Epoch {epoch} | Batch {idx+1} | Loss: {avg_loss:.4f} | Speed: {speed:.4f}s/样本\")\n",
    "        \n",
    "        print(f\"Epoch {epoch} 完成 | 平均损失: {total_loss/len(train_data):.4f}\")\n",
    "    return input_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c536551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(embeddings, id2word, file_path):\n",
    "    \"\"\"保存词向量\"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for idx, word in enumerate(id2word):\n",
    "            vec = ' '.join(map(str, embeddings[idx]))\n",
    "            f.write(f\"{word} {vec}\\n\")\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"计算余弦相似度\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2) + 1e-8)\n",
    "\n",
    "def find_most_similar(word, embeddings, word2id, id2word, top_k=10):\n",
    "    \"\"\"查找相似词\"\"\"\n",
    "    if word not in word2id:\n",
    "        return []\n",
    "    word_id = word2id[word]\n",
    "    target = embeddings[word_id]\n",
    "    similarities = []\n",
    "    for idx in range(1, len(id2word)):  # 跳过UNK\n",
    "        if idx == word_id:\n",
    "            continue\n",
    "        sim = cosine_similarity(target, embeddings[idx])\n",
    "        similarities.append((id2word[idx], sim))\n",
    "    similarities.sort(key=lambda x: -x[1])\n",
    "    return similarities[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37891eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(a, b, c, embeddings, word2id, id2word, top_k=5):\n",
    "    # 获取词向量\n",
    "    a_id = word2id.get(a, 0)\n",
    "    b_id = word2id.get(b, 0)\n",
    "    c_id = word2id.get(c, 0)\n",
    "    if a_id == 0 or b_id == 0 or c_id == 0:\n",
    "        print(f\"输入词中存在未知词：{a}, {b}, {c}\")\n",
    "        return []\n",
    "    \n",
    "    # 计算目标向量：vec(a) - vec(b) + vec(c)\n",
    "    vec_a = embeddings[a_id]\n",
    "    vec_b = embeddings[b_id]\n",
    "    vec_c = embeddings[c_id]\n",
    "    target_vec = vec_a - vec_b + vec_c\n",
    "    \n",
    "    # 查找最相似词\n",
    "    candidates = []\n",
    "    for idx, word in enumerate(id2word):\n",
    "        if idx == 0 or word in [a, b, c]:  # 跳过UNK和输入词\n",
    "            continue\n",
    "        vec = embeddings[idx]\n",
    "        score = cosine_similarity(target_vec, vec)\n",
    "        candidates.append((word, score))\n",
    "    \n",
    "    # 按相似度排序\n",
    "    candidates.sort(key=lambda x: -x[1])\n",
    "    return candidates[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cd56668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: 加载并预处理数据...\n",
      "词汇表大小: 4018\n"
     ]
    }
   ],
   "source": [
    " # ---------------------- 数据预处理 ----------------------\n",
    "print(\"Step 1: 加载并预处理数据...\")\n",
    "text = load_text(CORPUS_PATH, sample_ratio=SAMPLE_RATIO)\n",
    " word_freq, id2word, word2id = build_vocab(text, min_count=MIN_COUNT)\n",
    "print(f\"词汇表大小: {len(word2id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e7086d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: 生成训练数据...\n",
      "训练样本数: 148498\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------- 生成训练数据 ----------------------\n",
    "print(\"Step 2: 生成训练数据...\")\n",
    "train_data = generate_train_data(text, word2id, window_size=WINDOW_SIZE)\n",
    "print(f\"训练样本数: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "835b7fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: 构建霍夫曼树...\n",
      "示例路径长度: 11\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 构建霍夫曼树 ----------------------\n",
    "print(\"Step 3: 构建霍夫曼树...\")\n",
    "huffman_tree, word_to_path = build_huffman_tree(word_freq)\n",
    "print(f\"示例路径长度: {len(word_to_path[id2word[1]]['nodes'])}\")  # 检查第一个词的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55a7f438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: 初始化模型参数...\n",
      "词向量矩阵形状: (4018, 100)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 初始化参数 ----------------------\n",
    "print(\"Step 4: 初始化模型参数...\")\n",
    "vocab_size = len(word2id)\n",
    "input_emb, node_params = initialize_parameters(vocab_size, EMBEDDING_DIM, huffman_tree)\n",
    "print(f\"词向量矩阵形状: {input_emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3558e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: 开始训练...\n",
      "Epoch 0 | Batch 1000 | Loss: 6.2902 | Speed: 0.0183s/样本\n",
      "Epoch 0 | Batch 2000 | Loss: 6.3224 | Speed: 0.0181s/样本\n",
      "Epoch 0 | Batch 3000 | Loss: 6.3331 | Speed: 0.0179s/样本\n",
      "Epoch 0 | Batch 4000 | Loss: 6.3877 | Speed: 0.0178s/样本\n",
      "Epoch 0 | Batch 5000 | Loss: 6.3870 | Speed: 0.0178s/样本\n",
      "Epoch 0 | Batch 6000 | Loss: 6.3964 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 7000 | Loss: 6.4115 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 8000 | Loss: 6.4213 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 9000 | Loss: 6.4169 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 10000 | Loss: 6.4243 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 11000 | Loss: 6.4123 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 12000 | Loss: 6.4150 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 13000 | Loss: 6.4268 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 14000 | Loss: 6.4222 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 15000 | Loss: 6.4178 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 16000 | Loss: 6.4233 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 17000 | Loss: 6.4215 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 18000 | Loss: 6.4177 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 19000 | Loss: 6.4208 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 20000 | Loss: 6.4135 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 21000 | Loss: 6.4090 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 22000 | Loss: 6.3996 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 23000 | Loss: 6.4017 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 24000 | Loss: 6.3969 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 25000 | Loss: 6.3939 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 26000 | Loss: 6.3937 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 27000 | Loss: 6.3909 | Speed: 0.0177s/样本\n",
      "Epoch 0 | Batch 28000 | Loss: 6.3865 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 29000 | Loss: 6.3849 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 30000 | Loss: 6.3788 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 31000 | Loss: 6.3754 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 32000 | Loss: 6.3757 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 33000 | Loss: 6.3711 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 34000 | Loss: 6.3687 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 35000 | Loss: 6.3668 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 36000 | Loss: 6.3655 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 37000 | Loss: 6.3574 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 38000 | Loss: 6.3579 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 39000 | Loss: 6.3598 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 40000 | Loss: 6.3590 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 41000 | Loss: 6.3605 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 42000 | Loss: 6.3565 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 43000 | Loss: 6.3517 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 44000 | Loss: 6.3518 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 45000 | Loss: 6.3511 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 46000 | Loss: 6.3469 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 47000 | Loss: 6.3413 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 48000 | Loss: 6.3379 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 49000 | Loss: 6.3332 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 50000 | Loss: 6.3312 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 51000 | Loss: 6.3268 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 52000 | Loss: 6.3246 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 53000 | Loss: 6.3210 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 54000 | Loss: 6.3172 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 55000 | Loss: 6.3165 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 56000 | Loss: 6.3165 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 57000 | Loss: 6.3150 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 58000 | Loss: 6.3129 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 59000 | Loss: 6.3106 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 60000 | Loss: 6.3093 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 61000 | Loss: 6.3079 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 62000 | Loss: 6.3043 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 63000 | Loss: 6.3019 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 64000 | Loss: 6.2989 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 65000 | Loss: 6.2976 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 66000 | Loss: 6.2943 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 67000 | Loss: 6.2924 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 68000 | Loss: 6.2886 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 69000 | Loss: 6.2886 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 70000 | Loss: 6.2854 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 71000 | Loss: 6.2851 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 72000 | Loss: 6.2850 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 73000 | Loss: 6.2824 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 74000 | Loss: 6.2819 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 75000 | Loss: 6.2811 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 76000 | Loss: 6.2808 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 77000 | Loss: 6.2797 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 78000 | Loss: 6.2791 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 79000 | Loss: 6.2789 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 80000 | Loss: 6.2787 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 81000 | Loss: 6.2763 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 82000 | Loss: 6.2755 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 83000 | Loss: 6.2738 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 84000 | Loss: 6.2712 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 85000 | Loss: 6.2704 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 86000 | Loss: 6.2705 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 87000 | Loss: 6.2707 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 88000 | Loss: 6.2692 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 89000 | Loss: 6.2690 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 90000 | Loss: 6.2680 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 91000 | Loss: 6.2670 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 92000 | Loss: 6.2670 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 93000 | Loss: 6.2665 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 94000 | Loss: 6.2661 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 95000 | Loss: 6.2644 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 96000 | Loss: 6.2623 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 97000 | Loss: 6.2612 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 98000 | Loss: 6.2604 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 99000 | Loss: 6.2609 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 100000 | Loss: 6.2598 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 101000 | Loss: 6.2594 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 102000 | Loss: 6.2594 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 103000 | Loss: 6.2570 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 104000 | Loss: 6.2556 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 105000 | Loss: 6.2544 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 106000 | Loss: 6.2537 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 107000 | Loss: 6.2525 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 108000 | Loss: 6.2514 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 109000 | Loss: 6.2523 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 110000 | Loss: 6.2501 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 111000 | Loss: 6.2511 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 112000 | Loss: 6.2503 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 113000 | Loss: 6.2499 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 114000 | Loss: 6.2488 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 115000 | Loss: 6.2476 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 116000 | Loss: 6.2467 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 117000 | Loss: 6.2455 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 118000 | Loss: 6.2450 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 119000 | Loss: 6.2445 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 120000 | Loss: 6.2444 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 121000 | Loss: 6.2438 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 122000 | Loss: 6.2427 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 123000 | Loss: 6.2421 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 124000 | Loss: 6.2419 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 125000 | Loss: 6.2407 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 126000 | Loss: 6.2403 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 127000 | Loss: 6.2400 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 128000 | Loss: 6.2386 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 129000 | Loss: 6.2384 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 130000 | Loss: 6.2373 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 131000 | Loss: 6.2372 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 132000 | Loss: 6.2355 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 133000 | Loss: 6.2351 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 134000 | Loss: 6.2346 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 135000 | Loss: 6.2331 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 136000 | Loss: 6.2319 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 137000 | Loss: 6.2304 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 138000 | Loss: 6.2296 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 139000 | Loss: 6.2286 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 140000 | Loss: 6.2282 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 141000 | Loss: 6.2288 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 142000 | Loss: 6.2281 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 143000 | Loss: 6.2273 | Speed: 0.0176s/样本\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Batch 144000 | Loss: 6.2268 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 145000 | Loss: 6.2269 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 146000 | Loss: 6.2262 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 147000 | Loss: 6.2266 | Speed: 0.0176s/样本\n",
      "Epoch 0 | Batch 148000 | Loss: 6.2260 | Speed: 0.0176s/样本\n",
      "Epoch 0 完成 | 平均损失: 6.2254\n",
      "Epoch 1 | Batch 1000 | Loss: 6.0854 | Speed: 0.0180s/样本\n",
      "Epoch 1 | Batch 2000 | Loss: 6.0888 | Speed: 0.0178s/样本\n",
      "Epoch 1 | Batch 3000 | Loss: 6.1001 | Speed: 0.0177s/样本\n",
      "Epoch 1 | Batch 4000 | Loss: 6.1085 | Speed: 0.0177s/样本\n",
      "Epoch 1 | Batch 5000 | Loss: 6.1085 | Speed: 0.0177s/样本\n",
      "Epoch 1 | Batch 6000 | Loss: 6.0870 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 7000 | Loss: 6.0910 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 8000 | Loss: 6.1013 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 9000 | Loss: 6.0979 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 10000 | Loss: 6.1119 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 11000 | Loss: 6.1087 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 12000 | Loss: 6.1180 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 13000 | Loss: 6.1223 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 14000 | Loss: 6.1205 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 15000 | Loss: 6.1144 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 16000 | Loss: 6.1175 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 17000 | Loss: 6.1190 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 18000 | Loss: 6.1210 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 19000 | Loss: 6.1256 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 20000 | Loss: 6.1284 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 21000 | Loss: 6.1287 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 22000 | Loss: 6.1213 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 23000 | Loss: 6.1134 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 24000 | Loss: 6.1108 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 25000 | Loss: 6.1140 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 26000 | Loss: 6.1142 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 27000 | Loss: 6.1114 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 28000 | Loss: 6.1137 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 29000 | Loss: 6.1170 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 30000 | Loss: 6.1213 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 31000 | Loss: 6.1182 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 32000 | Loss: 6.1173 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 33000 | Loss: 6.1174 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 34000 | Loss: 6.1165 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 35000 | Loss: 6.1180 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 36000 | Loss: 6.1196 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 37000 | Loss: 6.1225 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 38000 | Loss: 6.1203 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 39000 | Loss: 6.1176 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 40000 | Loss: 6.1173 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 41000 | Loss: 6.1168 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 42000 | Loss: 6.1164 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 43000 | Loss: 6.1194 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 44000 | Loss: 6.1163 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 45000 | Loss: 6.1159 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 46000 | Loss: 6.1155 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 47000 | Loss: 6.1163 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 48000 | Loss: 6.1154 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 49000 | Loss: 6.1177 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 50000 | Loss: 6.1175 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 51000 | Loss: 6.1166 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 52000 | Loss: 6.1160 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 53000 | Loss: 6.1162 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 54000 | Loss: 6.1147 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 55000 | Loss: 6.1112 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 56000 | Loss: 6.1105 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 57000 | Loss: 6.1097 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 58000 | Loss: 6.1107 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 59000 | Loss: 6.1108 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 60000 | Loss: 6.1115 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 61000 | Loss: 6.1128 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 62000 | Loss: 6.1119 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 63000 | Loss: 6.1108 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 64000 | Loss: 6.1107 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 65000 | Loss: 6.1116 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 66000 | Loss: 6.1113 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 67000 | Loss: 6.1103 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 68000 | Loss: 6.1104 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 69000 | Loss: 6.1126 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 70000 | Loss: 6.1106 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 71000 | Loss: 6.1112 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 72000 | Loss: 6.1096 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 73000 | Loss: 6.1097 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 74000 | Loss: 6.1071 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 75000 | Loss: 6.1050 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 76000 | Loss: 6.1050 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 77000 | Loss: 6.1069 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 78000 | Loss: 6.1067 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 79000 | Loss: 6.1049 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 80000 | Loss: 6.1055 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 81000 | Loss: 6.1049 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 82000 | Loss: 6.1048 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 83000 | Loss: 6.1058 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 84000 | Loss: 6.1047 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 85000 | Loss: 6.1029 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 86000 | Loss: 6.1016 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 87000 | Loss: 6.1006 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 88000 | Loss: 6.1005 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 89000 | Loss: 6.1013 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 90000 | Loss: 6.1014 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 91000 | Loss: 6.1004 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 92000 | Loss: 6.1012 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 93000 | Loss: 6.1017 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 94000 | Loss: 6.1009 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 95000 | Loss: 6.0984 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 96000 | Loss: 6.0991 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 97000 | Loss: 6.0988 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 98000 | Loss: 6.0962 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 99000 | Loss: 6.0962 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 100000 | Loss: 6.0968 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 101000 | Loss: 6.0972 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 102000 | Loss: 6.0973 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 103000 | Loss: 6.0969 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 104000 | Loss: 6.0973 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 105000 | Loss: 6.0968 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 106000 | Loss: 6.0970 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 107000 | Loss: 6.0976 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 108000 | Loss: 6.0968 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 109000 | Loss: 6.0956 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 110000 | Loss: 6.0944 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 111000 | Loss: 6.0935 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 112000 | Loss: 6.0922 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 113000 | Loss: 6.0930 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 114000 | Loss: 6.0920 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 115000 | Loss: 6.0925 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 116000 | Loss: 6.0919 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 117000 | Loss: 6.0919 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 118000 | Loss: 6.0923 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 119000 | Loss: 6.0911 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 120000 | Loss: 6.0911 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 121000 | Loss: 6.0903 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 122000 | Loss: 6.0903 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 123000 | Loss: 6.0893 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 124000 | Loss: 6.0888 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 125000 | Loss: 6.0889 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 126000 | Loss: 6.0880 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 127000 | Loss: 6.0882 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 128000 | Loss: 6.0880 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 129000 | Loss: 6.0869 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 130000 | Loss: 6.0867 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 131000 | Loss: 6.0869 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 132000 | Loss: 6.0866 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 133000 | Loss: 6.0858 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 134000 | Loss: 6.0848 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 135000 | Loss: 6.0843 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 136000 | Loss: 6.0854 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 137000 | Loss: 6.0852 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 138000 | Loss: 6.0852 | Speed: 0.0175s/样本\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Batch 139000 | Loss: 6.0849 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 140000 | Loss: 6.0831 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 141000 | Loss: 6.0826 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 142000 | Loss: 6.0824 | Speed: 0.0176s/样本\n",
      "Epoch 1 | Batch 143000 | Loss: 6.0826 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 144000 | Loss: 6.0811 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 145000 | Loss: 6.0812 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 146000 | Loss: 6.0804 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 147000 | Loss: 6.0800 | Speed: 0.0175s/样本\n",
      "Epoch 1 | Batch 148000 | Loss: 6.0802 | Speed: 0.0175s/样本\n",
      "Epoch 1 完成 | 平均损失: 6.0803\n",
      "Epoch 2 | Batch 1000 | Loss: 6.0141 | Speed: 0.0174s/样本\n",
      "Epoch 2 | Batch 2000 | Loss: 6.0069 | Speed: 0.0174s/样本\n",
      "Epoch 2 | Batch 3000 | Loss: 6.0170 | Speed: 0.0174s/样本\n",
      "Epoch 2 | Batch 4000 | Loss: 6.0019 | Speed: 0.0174s/样本\n",
      "Epoch 2 | Batch 5000 | Loss: 5.9739 | Speed: 0.0176s/样本\n",
      "Epoch 2 | Batch 6000 | Loss: 5.9833 | Speed: 0.0176s/样本\n",
      "Epoch 2 | Batch 7000 | Loss: 5.9700 | Speed: 0.0176s/样本\n",
      "Epoch 2 | Batch 8000 | Loss: 5.9806 | Speed: 0.0176s/样本\n",
      "Epoch 2 | Batch 9000 | Loss: 5.9787 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 10000 | Loss: 5.9777 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 11000 | Loss: 5.9935 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 12000 | Loss: 5.9984 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 13000 | Loss: 5.9953 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 14000 | Loss: 5.9879 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 15000 | Loss: 5.9850 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 16000 | Loss: 5.9838 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 17000 | Loss: 5.9910 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 18000 | Loss: 5.9904 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 19000 | Loss: 5.9951 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 20000 | Loss: 5.9959 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 21000 | Loss: 5.9941 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 22000 | Loss: 5.9921 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 23000 | Loss: 5.9915 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 24000 | Loss: 5.9808 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 25000 | Loss: 5.9795 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 26000 | Loss: 5.9780 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 27000 | Loss: 5.9815 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 28000 | Loss: 5.9878 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 29000 | Loss: 5.9844 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 30000 | Loss: 5.9843 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 31000 | Loss: 5.9834 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 32000 | Loss: 5.9803 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 33000 | Loss: 5.9804 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 34000 | Loss: 5.9783 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 35000 | Loss: 5.9804 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 36000 | Loss: 5.9854 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 37000 | Loss: 5.9804 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 38000 | Loss: 5.9811 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 39000 | Loss: 5.9792 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 40000 | Loss: 5.9769 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 41000 | Loss: 5.9759 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 42000 | Loss: 5.9765 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 43000 | Loss: 5.9774 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 44000 | Loss: 5.9749 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 45000 | Loss: 5.9747 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 46000 | Loss: 5.9759 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 47000 | Loss: 5.9771 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 48000 | Loss: 5.9789 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 49000 | Loss: 5.9770 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 50000 | Loss: 5.9759 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 51000 | Loss: 5.9747 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 52000 | Loss: 5.9754 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 53000 | Loss: 5.9750 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 54000 | Loss: 5.9779 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 55000 | Loss: 5.9780 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 56000 | Loss: 5.9775 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 57000 | Loss: 5.9791 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 58000 | Loss: 5.9761 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 59000 | Loss: 5.9743 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 60000 | Loss: 5.9768 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 61000 | Loss: 5.9751 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 62000 | Loss: 5.9747 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 63000 | Loss: 5.9766 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 64000 | Loss: 5.9757 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 65000 | Loss: 5.9757 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 66000 | Loss: 5.9762 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 67000 | Loss: 5.9761 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 68000 | Loss: 5.9788 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 69000 | Loss: 5.9806 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 70000 | Loss: 5.9792 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 71000 | Loss: 5.9780 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 72000 | Loss: 5.9784 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 73000 | Loss: 5.9798 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 74000 | Loss: 5.9791 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 75000 | Loss: 5.9777 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 76000 | Loss: 5.9780 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 77000 | Loss: 5.9766 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 78000 | Loss: 5.9758 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 79000 | Loss: 5.9762 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 80000 | Loss: 5.9779 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 81000 | Loss: 5.9763 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 82000 | Loss: 5.9759 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 83000 | Loss: 5.9768 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 84000 | Loss: 5.9764 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 85000 | Loss: 5.9766 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 86000 | Loss: 5.9762 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 87000 | Loss: 5.9787 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 88000 | Loss: 5.9776 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 89000 | Loss: 5.9758 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 90000 | Loss: 5.9754 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 91000 | Loss: 5.9760 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 92000 | Loss: 5.9758 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 93000 | Loss: 5.9760 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 94000 | Loss: 5.9755 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 95000 | Loss: 5.9751 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 96000 | Loss: 5.9755 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 97000 | Loss: 5.9754 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 98000 | Loss: 5.9736 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 99000 | Loss: 5.9753 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 100000 | Loss: 5.9746 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 101000 | Loss: 5.9740 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 102000 | Loss: 5.9750 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 103000 | Loss: 5.9741 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 104000 | Loss: 5.9734 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 105000 | Loss: 5.9734 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 106000 | Loss: 5.9745 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 107000 | Loss: 5.9751 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 108000 | Loss: 5.9744 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 109000 | Loss: 5.9754 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 110000 | Loss: 5.9756 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 111000 | Loss: 5.9763 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 112000 | Loss: 5.9762 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 113000 | Loss: 5.9773 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 114000 | Loss: 5.9763 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 115000 | Loss: 5.9765 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 116000 | Loss: 5.9770 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 117000 | Loss: 5.9776 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 118000 | Loss: 5.9767 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 119000 | Loss: 5.9759 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 120000 | Loss: 5.9760 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 121000 | Loss: 5.9760 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 122000 | Loss: 5.9763 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 123000 | Loss: 5.9751 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 124000 | Loss: 5.9750 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 125000 | Loss: 5.9747 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 126000 | Loss: 5.9746 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 127000 | Loss: 5.9741 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 128000 | Loss: 5.9739 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 129000 | Loss: 5.9757 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 130000 | Loss: 5.9748 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 131000 | Loss: 5.9748 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 132000 | Loss: 5.9745 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 133000 | Loss: 5.9737 | Speed: 0.0175s/样本\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Batch 134000 | Loss: 5.9733 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 135000 | Loss: 5.9718 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 136000 | Loss: 5.9719 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 137000 | Loss: 5.9728 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 138000 | Loss: 5.9735 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 139000 | Loss: 5.9737 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 140000 | Loss: 5.9731 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 141000 | Loss: 5.9725 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 142000 | Loss: 5.9720 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 143000 | Loss: 5.9714 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 144000 | Loss: 5.9712 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 145000 | Loss: 5.9706 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 146000 | Loss: 5.9699 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 147000 | Loss: 5.9704 | Speed: 0.0175s/样本\n",
      "Epoch 2 | Batch 148000 | Loss: 5.9705 | Speed: 0.0175s/样本\n",
      "Epoch 2 完成 | 平均损失: 5.9702\n",
      "Epoch 3 | Batch 1000 | Loss: 5.7552 | Speed: 0.0190s/样本\n",
      "Epoch 3 | Batch 2000 | Loss: 5.8730 | Speed: 0.0193s/样本\n",
      "Epoch 3 | Batch 3000 | Loss: 5.8735 | Speed: 0.0195s/样本\n",
      "Epoch 3 | Batch 4000 | Loss: 5.8505 | Speed: 0.0194s/样本\n",
      "Epoch 3 | Batch 5000 | Loss: 5.8669 | Speed: 0.0193s/样本\n",
      "Epoch 3 | Batch 6000 | Loss: 5.8549 | Speed: 0.0194s/样本\n",
      "Epoch 3 | Batch 7000 | Loss: 5.8566 | Speed: 0.0196s/样本\n",
      "Epoch 3 | Batch 8000 | Loss: 5.8402 | Speed: 0.0195s/样本\n",
      "Epoch 3 | Batch 9000 | Loss: 5.8387 | Speed: 0.0195s/样本\n",
      "Epoch 3 | Batch 10000 | Loss: 5.8261 | Speed: 0.0195s/样本\n",
      "Epoch 3 | Batch 11000 | Loss: 5.8293 | Speed: 0.0195s/样本\n",
      "Epoch 3 | Batch 12000 | Loss: 5.8348 | Speed: 0.0195s/样本\n",
      "Epoch 3 | Batch 13000 | Loss: 5.8351 | Speed: 0.0195s/样本\n",
      "Epoch 3 | Batch 14000 | Loss: 5.8336 | Speed: 0.0195s/样本\n",
      "Epoch 3 | Batch 15000 | Loss: 5.8395 | Speed: 0.0194s/样本\n",
      "Epoch 3 | Batch 16000 | Loss: 5.8388 | Speed: 0.0194s/样本\n",
      "Epoch 3 | Batch 17000 | Loss: 5.8394 | Speed: 0.0194s/样本\n",
      "Epoch 3 | Batch 18000 | Loss: 5.8387 | Speed: 0.0193s/样本\n",
      "Epoch 3 | Batch 19000 | Loss: 5.8360 | Speed: 0.0193s/样本\n",
      "Epoch 3 | Batch 20000 | Loss: 5.8295 | Speed: 0.0192s/样本\n",
      "Epoch 3 | Batch 21000 | Loss: 5.8393 | Speed: 0.0192s/样本\n",
      "Epoch 3 | Batch 22000 | Loss: 5.8468 | Speed: 0.0192s/样本\n",
      "Epoch 3 | Batch 23000 | Loss: 5.8471 | Speed: 0.0191s/样本\n",
      "Epoch 3 | Batch 24000 | Loss: 5.8490 | Speed: 0.0191s/样本\n",
      "Epoch 3 | Batch 25000 | Loss: 5.8529 | Speed: 0.0190s/样本\n",
      "Epoch 3 | Batch 26000 | Loss: 5.8570 | Speed: 0.0189s/样本\n",
      "Epoch 3 | Batch 27000 | Loss: 5.8607 | Speed: 0.0189s/样本\n",
      "Epoch 3 | Batch 28000 | Loss: 5.8661 | Speed: 0.0188s/样本\n",
      "Epoch 3 | Batch 29000 | Loss: 5.8675 | Speed: 0.0188s/样本\n",
      "Epoch 3 | Batch 30000 | Loss: 5.8665 | Speed: 0.0187s/样本\n",
      "Epoch 3 | Batch 31000 | Loss: 5.8628 | Speed: 0.0187s/样本\n",
      "Epoch 3 | Batch 32000 | Loss: 5.8640 | Speed: 0.0186s/样本\n",
      "Epoch 3 | Batch 33000 | Loss: 5.8599 | Speed: 0.0186s/样本\n",
      "Epoch 3 | Batch 34000 | Loss: 5.8610 | Speed: 0.0186s/样本\n",
      "Epoch 3 | Batch 35000 | Loss: 5.8616 | Speed: 0.0185s/样本\n",
      "Epoch 3 | Batch 36000 | Loss: 5.8586 | Speed: 0.0185s/样本\n",
      "Epoch 3 | Batch 37000 | Loss: 5.8595 | Speed: 0.0185s/样本\n",
      "Epoch 3 | Batch 38000 | Loss: 5.8613 | Speed: 0.0184s/样本\n",
      "Epoch 3 | Batch 39000 | Loss: 5.8640 | Speed: 0.0184s/样本\n",
      "Epoch 3 | Batch 40000 | Loss: 5.8630 | Speed: 0.0184s/样本\n",
      "Epoch 3 | Batch 41000 | Loss: 5.8665 | Speed: 0.0184s/样本\n",
      "Epoch 3 | Batch 42000 | Loss: 5.8671 | Speed: 0.0183s/样本\n",
      "Epoch 3 | Batch 43000 | Loss: 5.8696 | Speed: 0.0183s/样本\n",
      "Epoch 3 | Batch 44000 | Loss: 5.8688 | Speed: 0.0183s/样本\n",
      "Epoch 3 | Batch 45000 | Loss: 5.8692 | Speed: 0.0183s/样本\n",
      "Epoch 3 | Batch 46000 | Loss: 5.8708 | Speed: 0.0183s/样本\n",
      "Epoch 3 | Batch 47000 | Loss: 5.8738 | Speed: 0.0182s/样本\n",
      "Epoch 3 | Batch 48000 | Loss: 5.8726 | Speed: 0.0182s/样本\n",
      "Epoch 3 | Batch 49000 | Loss: 5.8722 | Speed: 0.0182s/样本\n",
      "Epoch 3 | Batch 50000 | Loss: 5.8759 | Speed: 0.0182s/样本\n",
      "Epoch 3 | Batch 51000 | Loss: 5.8767 | Speed: 0.0182s/样本\n",
      "Epoch 3 | Batch 52000 | Loss: 5.8766 | Speed: 0.0182s/样本\n",
      "Epoch 3 | Batch 53000 | Loss: 5.8719 | Speed: 0.0182s/样本\n",
      "Epoch 3 | Batch 54000 | Loss: 5.8707 | Speed: 0.0182s/样本\n",
      "Epoch 3 | Batch 55000 | Loss: 5.8664 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 56000 | Loss: 5.8664 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 57000 | Loss: 5.8665 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 58000 | Loss: 5.8687 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 59000 | Loss: 5.8702 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 60000 | Loss: 5.8677 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 61000 | Loss: 5.8661 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 62000 | Loss: 5.8660 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 63000 | Loss: 5.8684 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 64000 | Loss: 5.8677 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 65000 | Loss: 5.8673 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 66000 | Loss: 5.8674 | Speed: 0.0181s/样本\n",
      "Epoch 3 | Batch 67000 | Loss: 5.8686 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 68000 | Loss: 5.8678 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 69000 | Loss: 5.8684 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 70000 | Loss: 5.8698 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 71000 | Loss: 5.8706 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 72000 | Loss: 5.8692 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 73000 | Loss: 5.8709 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 74000 | Loss: 5.8718 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 75000 | Loss: 5.8700 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 76000 | Loss: 5.8710 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 77000 | Loss: 5.8687 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 78000 | Loss: 5.8700 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 79000 | Loss: 5.8704 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 80000 | Loss: 5.8706 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 81000 | Loss: 5.8700 | Speed: 0.0180s/样本\n",
      "Epoch 3 | Batch 82000 | Loss: 5.8711 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 83000 | Loss: 5.8714 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 84000 | Loss: 5.8708 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 85000 | Loss: 5.8712 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 86000 | Loss: 5.8712 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 87000 | Loss: 5.8737 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 88000 | Loss: 5.8749 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 89000 | Loss: 5.8737 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 90000 | Loss: 5.8740 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 91000 | Loss: 5.8745 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 92000 | Loss: 5.8742 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 93000 | Loss: 5.8753 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 94000 | Loss: 5.8749 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 95000 | Loss: 5.8752 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 96000 | Loss: 5.8747 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 97000 | Loss: 5.8746 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 98000 | Loss: 5.8741 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 99000 | Loss: 5.8743 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 100000 | Loss: 5.8739 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 101000 | Loss: 5.8738 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 102000 | Loss: 5.8726 | Speed: 0.0179s/样本\n",
      "Epoch 3 | Batch 103000 | Loss: 5.8731 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 104000 | Loss: 5.8723 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 105000 | Loss: 5.8730 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 106000 | Loss: 5.8735 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 107000 | Loss: 5.8733 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 108000 | Loss: 5.8744 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 109000 | Loss: 5.8735 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 110000 | Loss: 5.8740 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 111000 | Loss: 5.8734 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 112000 | Loss: 5.8730 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 113000 | Loss: 5.8712 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 114000 | Loss: 5.8700 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 115000 | Loss: 5.8707 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 116000 | Loss: 5.8703 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 117000 | Loss: 5.8697 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 118000 | Loss: 5.8692 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 119000 | Loss: 5.8694 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 120000 | Loss: 5.8701 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 121000 | Loss: 5.8700 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 122000 | Loss: 5.8690 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 123000 | Loss: 5.8687 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 124000 | Loss: 5.8682 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 125000 | Loss: 5.8691 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 126000 | Loss: 5.8681 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 127000 | Loss: 5.8679 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 128000 | Loss: 5.8697 | Speed: 0.0178s/样本\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Batch 129000 | Loss: 5.8687 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 130000 | Loss: 5.8687 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 131000 | Loss: 5.8685 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 132000 | Loss: 5.8687 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 133000 | Loss: 5.8684 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 134000 | Loss: 5.8671 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 135000 | Loss: 5.8678 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 136000 | Loss: 5.8679 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 137000 | Loss: 5.8678 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 138000 | Loss: 5.8676 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 139000 | Loss: 5.8680 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 140000 | Loss: 5.8670 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 141000 | Loss: 5.8674 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 142000 | Loss: 5.8660 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 143000 | Loss: 5.8653 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 144000 | Loss: 5.8647 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 145000 | Loss: 5.8652 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 146000 | Loss: 5.8661 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 147000 | Loss: 5.8665 | Speed: 0.0178s/样本\n",
      "Epoch 3 | Batch 148000 | Loss: 5.8661 | Speed: 0.0178s/样本\n",
      "Epoch 3 完成 | 平均损失: 5.8662\n",
      "Epoch 4 | Batch 1000 | Loss: 5.7144 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 2000 | Loss: 5.7936 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 3000 | Loss: 5.8156 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 4000 | Loss: 5.8036 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 5000 | Loss: 5.7845 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 6000 | Loss: 5.7649 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 7000 | Loss: 5.7591 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 8000 | Loss: 5.7409 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 9000 | Loss: 5.7408 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 10000 | Loss: 5.7422 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 11000 | Loss: 5.7518 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 12000 | Loss: 5.7508 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 13000 | Loss: 5.7516 | Speed: 0.0178s/样本\n",
      "Epoch 4 | Batch 14000 | Loss: 5.7471 | Speed: 0.0180s/样本\n",
      "Epoch 4 | Batch 15000 | Loss: 5.7565 | Speed: 0.0181s/样本\n",
      "Epoch 4 | Batch 16000 | Loss: 5.7593 | Speed: 0.0181s/样本\n",
      "Epoch 4 | Batch 17000 | Loss: 5.7621 | Speed: 0.0181s/样本\n",
      "Epoch 4 | Batch 18000 | Loss: 5.7632 | Speed: 0.0181s/样本\n",
      "Epoch 4 | Batch 19000 | Loss: 5.7631 | Speed: 0.0181s/样本\n",
      "Epoch 4 | Batch 20000 | Loss: 5.7624 | Speed: 0.0181s/样本\n",
      "Epoch 4 | Batch 21000 | Loss: 5.7625 | Speed: 0.0181s/样本\n",
      "Epoch 4 | Batch 22000 | Loss: 5.7652 | Speed: 0.0181s/样本\n",
      "Epoch 4 | Batch 23000 | Loss: 5.7659 | Speed: 0.0181s/样本\n",
      "Epoch 4 | Batch 24000 | Loss: 5.7674 | Speed: 0.0182s/样本\n",
      "Epoch 4 | Batch 25000 | Loss: 5.7630 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 26000 | Loss: 5.7662 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 27000 | Loss: 5.7596 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 28000 | Loss: 5.7537 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 29000 | Loss: 5.7513 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 30000 | Loss: 5.7534 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 31000 | Loss: 5.7553 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 32000 | Loss: 5.7533 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 33000 | Loss: 5.7523 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 34000 | Loss: 5.7552 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 35000 | Loss: 5.7544 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 36000 | Loss: 5.7543 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 37000 | Loss: 5.7536 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 38000 | Loss: 5.7534 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 39000 | Loss: 5.7537 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 40000 | Loss: 5.7518 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 41000 | Loss: 5.7538 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 42000 | Loss: 5.7588 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 43000 | Loss: 5.7578 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 44000 | Loss: 5.7581 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 45000 | Loss: 5.7578 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 46000 | Loss: 5.7578 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 47000 | Loss: 5.7557 | Speed: 0.0188s/样本\n",
      "Epoch 4 | Batch 48000 | Loss: 5.7531 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 49000 | Loss: 5.7511 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 50000 | Loss: 5.7504 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 51000 | Loss: 5.7514 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 52000 | Loss: 5.7540 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 53000 | Loss: 5.7546 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 54000 | Loss: 5.7525 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 55000 | Loss: 5.7531 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 56000 | Loss: 5.7527 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 57000 | Loss: 5.7548 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 58000 | Loss: 5.7564 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 59000 | Loss: 5.7560 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 60000 | Loss: 5.7584 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 61000 | Loss: 5.7582 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 62000 | Loss: 5.7602 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 63000 | Loss: 5.7605 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 64000 | Loss: 5.7622 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 65000 | Loss: 5.7591 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 66000 | Loss: 5.7607 | Speed: 0.0187s/样本\n",
      "Epoch 4 | Batch 67000 | Loss: 5.7633 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 68000 | Loss: 5.7627 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 69000 | Loss: 5.7643 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 70000 | Loss: 5.7625 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 71000 | Loss: 5.7619 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 72000 | Loss: 5.7629 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 73000 | Loss: 5.7605 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 74000 | Loss: 5.7607 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 75000 | Loss: 5.7609 | Speed: 0.0186s/样本\n",
      "Epoch 4 | Batch 76000 | Loss: 5.7610 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 77000 | Loss: 5.7626 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 78000 | Loss: 5.7635 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 79000 | Loss: 5.7634 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 80000 | Loss: 5.7632 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 81000 | Loss: 5.7643 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 82000 | Loss: 5.7644 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 83000 | Loss: 5.7645 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 84000 | Loss: 5.7648 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 85000 | Loss: 5.7673 | Speed: 0.0185s/样本\n",
      "Epoch 4 | Batch 86000 | Loss: 5.7693 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 87000 | Loss: 5.7681 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 88000 | Loss: 5.7669 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 89000 | Loss: 5.7654 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 90000 | Loss: 5.7649 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 91000 | Loss: 5.7664 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 92000 | Loss: 5.7665 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 93000 | Loss: 5.7656 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 94000 | Loss: 5.7644 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 95000 | Loss: 5.7652 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 96000 | Loss: 5.7644 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 97000 | Loss: 5.7658 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 98000 | Loss: 5.7667 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 99000 | Loss: 5.7679 | Speed: 0.0184s/样本\n",
      "Epoch 4 | Batch 100000 | Loss: 5.7674 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 101000 | Loss: 5.7668 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 102000 | Loss: 5.7652 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 103000 | Loss: 5.7654 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 104000 | Loss: 5.7662 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 105000 | Loss: 5.7668 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 106000 | Loss: 5.7679 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 107000 | Loss: 5.7690 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 108000 | Loss: 5.7692 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 109000 | Loss: 5.7698 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 110000 | Loss: 5.7696 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 111000 | Loss: 5.7704 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 112000 | Loss: 5.7708 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 113000 | Loss: 5.7702 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 114000 | Loss: 5.7711 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 115000 | Loss: 5.7700 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 116000 | Loss: 5.7689 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 117000 | Loss: 5.7695 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 118000 | Loss: 5.7695 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 119000 | Loss: 5.7700 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 120000 | Loss: 5.7713 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 121000 | Loss: 5.7702 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 122000 | Loss: 5.7706 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 123000 | Loss: 5.7706 | Speed: 0.0183s/样本\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Batch 124000 | Loss: 5.7696 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 125000 | Loss: 5.7691 | Speed: 0.0182s/样本\n",
      "Epoch 4 | Batch 126000 | Loss: 5.7695 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 127000 | Loss: 5.7702 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 128000 | Loss: 5.7701 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 129000 | Loss: 5.7701 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 130000 | Loss: 5.7700 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 131000 | Loss: 5.7697 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 132000 | Loss: 5.7696 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 133000 | Loss: 5.7701 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 134000 | Loss: 5.7692 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 135000 | Loss: 5.7689 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 136000 | Loss: 5.7694 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 137000 | Loss: 5.7698 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 138000 | Loss: 5.7688 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 139000 | Loss: 5.7696 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 140000 | Loss: 5.7684 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 141000 | Loss: 5.7693 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 142000 | Loss: 5.7685 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 143000 | Loss: 5.7673 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 144000 | Loss: 5.7673 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 145000 | Loss: 5.7683 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 146000 | Loss: 5.7687 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 147000 | Loss: 5.7693 | Speed: 0.0183s/样本\n",
      "Epoch 4 | Batch 148000 | Loss: 5.7703 | Speed: 0.0183s/样本\n",
      "Epoch 4 完成 | 平均损失: 5.7695\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 训练模型 ----------------------\n",
    "print(\"Step 5: 开始训练...\")\n",
    "trained_emb = train_model(\n",
    "train_data, input_emb, node_params, word_to_path, id2word,\n",
    "num_epochs=NUM_EPOCHS, lr=0.025\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b5c49b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: 保存词向量并测试...\n"
     ]
    }
   ],
   "source": [
    " # ---------------------- 保存和测试 ----------------------\n",
    "print(\"Step 6: 保存词向量并测试...\")\n",
    "save_embeddings(trained_emb, id2word, \"word_vectors.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b35b40e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与 'king' 最相似的词:\n",
      "lack: 0.8719\n",
      "comparison: 0.8660\n",
      "slow: 0.8569\n",
      "walk: 0.8349\n",
      "tasks: 0.8338\n",
      "consist: 0.8290\n",
      "abuse: 0.8231\n",
      "course: 0.8145\n",
      "heads: 0.8117\n",
      "start: 0.8115\n"
     ]
    }
   ],
   "source": [
    " # 测试相似词\n",
    "test_word = \"king\"\n",
    "similar_words = find_most_similar(test_word, trained_emb, word2id, id2word)\n",
    "print(f\"与 '{test_word}' 最相似的词:\")\n",
    "for word, sim in similar_words:\n",
    "    print(f\"{word}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c096dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 测试类比任务\n",
    "print(\"\\n类比任务测试：\")\n",
    "a, b, c = \"man\", \"woman\", \"king\"\n",
    "results = analogy(a, b, c, trained_emb, word2id, id2word)\n",
    "print(f\"{a} : {b} :: {c} : ?\")\n",
    "for word, score in results:\n",
    "    print(f\"{word}: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
